{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histology Tissue Classification Project (HTCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) K. Mader / U. Michelucci 2018-2019\n",
    "\n",
    "# Overview\n",
    "The dataset serves as a much more interesting MNIST or CIFAR10 problem for biologists by focusing on histology tiles from patients with colorectal cancer. In particular, the data has 8 different classes of tissue (but Cancer/Not Cancer can also be an interesting problem).\n",
    "\n",
    "The dataset has been adapted for the course by K. Mader (kevin.mader@gmail.com), and is available on kaggle: https://goo.gl/26zj41\n",
    "\n",
    "# Challenge\n",
    "- Classify tiles correctly into one of the eight classes\n",
    "- Which classes are most frequently confused?\n",
    "- What features can be used (like texture, see scikit-image) to improve classification?\n",
    "- How can these models be applied to the much larger 5000x5000 models? \n",
    "How can this be done efficiently?\n",
    "\n",
    "# Acknowledgements\n",
    "The dataset has been copied from Zenodo: https://zenodo.org/record/53169#.W6HwwP4zbOQ\n",
    "\n",
    "made by: Kather, Jakob Nikolas; Zöllner, Frank Gerrit; Bianconi, Francesco; Melchers, \n",
    "    Susanne M; Schad, Lothar R; Gaiser, Timo; Marx, Alexander; Weis, Cleo-Aron\n",
    "\n",
    "The copy here is to make it more accessible to Kaggle users and allow kernels \n",
    "providing basic analysis of the data\n",
    "\n",
    "Content\n",
    "This data set represents a collection of textures in histological images of \n",
    "human colorectal cancer. It contains two files:\n",
    "\n",
    "    Kather_texture_2016_image_tiles_5000.zip\": a zipped folder containing 5000 \n",
    "    histological images of 150 * 150 px each (74 * 74 µm). Each image belongs \n",
    "    to exactly one of eight tissue categories (specified by the folder name). \n",
    "    \n",
    "    Kather_texture_2016_larger_images_10.zip\": a zipped folder containing 10 \n",
    "    larger histological images of 5000 x 5000 px each. These images contain \n",
    "    more than one tissue type. Image format\n",
    "\n",
    "All images are RGB, 0.495 µm per pixel, digitized with an Aperio ScanScope \n",
    "(Aperio/Leica biosystems), magnification 20x. Histological samples are fully \n",
    "anonymized images of formalin-fixed paraffin-embedded human colorectal \n",
    "adenocarcinomas (primary tumors) from our pathology archive (Institute of Pathology, \n",
    "University Medical Center Mannheim, Heidelberg University, Mannheim, Germany).\n",
    "\n",
    "Additionally the files has been prepared to resemble the MNIST dataset, meaning that you will also find the following files\n",
    "\n",
    "- HTCP_8_8_L - \n",
    "- HTCP_8_8_RGB -\n",
    "- HTCP_28_28_L -\n",
    "- HTCP_28_28_RGB - \n",
    "- HTCP_64_64_L\n",
    "\n",
    "# Ethics statement\n",
    "All experiments were approved by the institutional ethics board (medical ethics board II, University Medical Center Mannheim, Heidelberg University, Germany; approval 2015-868R-MA). The institutional ethics board waived the need for informed consent for this retrospective analysis of anonymized samples. All experiments were carried out in accordance with the approved guidelines and with the Declaration of Helsinki.\n",
    "\n",
    "# More information / data usage\n",
    "For more information, please refer to the following article. Please cite this article when using the data set.\n",
    "\n",
    "Kather JN, Weis CA, Bianconi F, Melchers SM, Schad LR, Gaiser T, Marx A, Zollner F: Multi-class texture analysis in colorectal cancer histology (2016), Scientific Reports (in press)\n",
    "\n",
    "# Contact\n",
    "For questions, please contact: Dr. Jakob Nikolas Kather http://orcid.org/0000-0002-3730-5348 ResearcherID: D-4279-2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is composed of two datasets:\n",
    "\n",
    "- The small images that will be used to test the classification models\n",
    "- The big microscope images (5000x5000)\n",
    "\n",
    "The first dataset is quite small and can be found in the same github repository where you find this file. The second are much bigger (250 Mb and 700 Mb) and cannot be uploaded on github, so you can get them on  kaggle: https://goo.gl/hkRSke  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(some_image):\n",
    "    \n",
    "    some_digit_image = some_image.values.reshape(28,28)\n",
    "\n",
    "    plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_name(idx):\n",
    "    \n",
    "    if (idx == 1):\n",
    "        return '(1) TUMOR'\n",
    "    elif (idx == 2):\n",
    "        return '(2) STROMA'\n",
    "    elif (idx == 3):\n",
    "        return '(3) COMPLEX'\n",
    "    elif (idx == 4):\n",
    "        return '(4) LYMPHO'\n",
    "    elif (idx == 5):\n",
    "        return '(5) DEBRIS'\n",
    "    elif (idx == 6):\n",
    "        return '(6) MUCOSA'\n",
    "    elif (idx == 7):\n",
    "        return '(7) ADIPOSE'\n",
    "    elif (idx == 8):\n",
    "        return '(8) EMPTY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/HTCP_28_28_L.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an array with labels (not yet one-encoded) and one for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yinput = data['label']\n",
    "Xinput = data.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first records of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel0774</th>\n",
       "      <th>pixel0775</th>\n",
       "      <th>pixel0776</th>\n",
       "      <th>pixel0777</th>\n",
       "      <th>pixel0778</th>\n",
       "      <th>pixel0779</th>\n",
       "      <th>pixel0780</th>\n",
       "      <th>pixel0781</th>\n",
       "      <th>pixel0782</th>\n",
       "      <th>pixel0783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>110</td>\n",
       "      <td>154</td>\n",
       "      <td>160</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>139</td>\n",
       "      <td>184</td>\n",
       "      <td>164</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>103</td>\n",
       "      <td>73</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>152</td>\n",
       "      <td>130</td>\n",
       "      <td>96</td>\n",
       "      <td>133</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>57</td>\n",
       "      <td>46</td>\n",
       "      <td>67</td>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127</td>\n",
       "      <td>137</td>\n",
       "      <td>121</td>\n",
       "      <td>140</td>\n",
       "      <td>170</td>\n",
       "      <td>111</td>\n",
       "      <td>128</td>\n",
       "      <td>117</td>\n",
       "      <td>60</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>143</td>\n",
       "      <td>119</td>\n",
       "      <td>148</td>\n",
       "      <td>140</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>101</td>\n",
       "      <td>106</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>131</td>\n",
       "      <td>109</td>\n",
       "      <td>97</td>\n",
       "      <td>102</td>\n",
       "      <td>71</td>\n",
       "      <td>93</td>\n",
       "      <td>120</td>\n",
       "      <td>84</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>141</td>\n",
       "      <td>121</td>\n",
       "      <td>132</td>\n",
       "      <td>110</td>\n",
       "      <td>131</td>\n",
       "      <td>119</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>117</td>\n",
       "      <td>121</td>\n",
       "      <td>136</td>\n",
       "      <td>178</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "      <td>189</td>\n",
       "      <td>149</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "0        101        110        154        160         95         44   \n",
       "1         67         66         69         76         80         57   \n",
       "2        127        137        121        140        170        111   \n",
       "3         80         90        101        106        120        100   \n",
       "4        153        141        121        132        110        131   \n",
       "\n",
       "   pixel0006  pixel0007  pixel0008  pixel0009    ...      pixel0774  \\\n",
       "0        139        184        164        160    ...            128   \n",
       "1         46         67         90         77    ...             57   \n",
       "2        128        117         60        105    ...             69   \n",
       "3         99         66         63         91    ...            154   \n",
       "4        119         99        101         91    ...            134   \n",
       "\n",
       "   pixel0775  pixel0776  pixel0777  pixel0778  pixel0779  pixel0780  \\\n",
       "0        103         73         72         75        152        130   \n",
       "1         58         65         74         80         81         83   \n",
       "2         90        100        143        119        148        140   \n",
       "3        131        109         97        102         71         93   \n",
       "4        117        121        136        178        192        210   \n",
       "\n",
       "   pixel0781  pixel0782  pixel0783  \n",
       "0         96        133        159  \n",
       "1         77         75         73  \n",
       "2        193        146         97  \n",
       "3        120         84         62  \n",
       "4        189        149        155  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xinput.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yinput.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets has 5000 images, each 28x28 in gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xinput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yinput.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot an image of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 7, 6, 8, 1, 4, 3], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yinput.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_element_with_label (Xinput, lbls, lbl):\n",
    "    tmp = lbls == lbl\n",
    "    subset = Xinput[tmp]\n",
    "    return subset.iloc[randint(1,subset.shape[0])]\n",
    "\n",
    "labels_overview = np.empty([10,784])\n",
    "for i in range (1,9):\n",
    "    img = get_random_element_with_label(Xinput, yinput, i)\n",
    "    labels_overview[i,:] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1080 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(8,15));\n",
    "count = 1\n",
    "for i in range(1,9):\n",
    "    plt.subplot(5,2,count)\n",
    "    count = count + 1\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.title(get_label_name(i))\n",
    "    some_digit_image = labels_overview[i,:].reshape(28,28)\n",
    "    plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 0 appear 0 times\n",
      "image 1 appear 625 times\n",
      "image 2 appear 625 times\n",
      "image 3 appear 625 times\n",
      "image 4 appear 625 times\n",
      "image 5 appear 625 times\n",
      "image 6 appear 625 times\n",
      "image 7 appear 625 times\n",
      "image 8 appear 625 times\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(9):\n",
    "    print (\"image\", i, \"appear\", np.count_nonzero(yinput == i), \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 0 makes 0.0 % of the 5000 observations\n",
      "image 1 makes 12.5 % of the 5000 observations\n",
      "image 2 makes 12.5 % of the 5000 observations\n",
      "image 3 makes 12.5 % of the 5000 observations\n",
      "image 4 makes 12.5 % of the 5000 observations\n",
      "image 5 makes 12.5 % of the 5000 observations\n",
      "image 6 makes 12.5 % of the 5000 observations\n",
      "image 7 makes 12.5 % of the 5000 observations\n",
      "image 8 makes 12.5 % of the 5000 observations\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(9):\n",
    "    print (\"image\", i, \"makes\", np.around(np.count_nonzero(yinput == i)/5000.0*100.0, decimals=1), \"% of the 5000 observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ylabels, ylabels_test = train_test_split(Xinput, yinput, test_size=0.2, stratify=yinput, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xtrain.transpose()\n",
    "labels = ylabels.values.reshape(1, 4000)-1\n",
    "labels_ = np.zeros((4000, 9))\n",
    "labels_[np.arange(4000), labels] = 1\n",
    "labels_ = labels_.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 4000)\n",
      "(9, 4000)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(labels_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xtest.transpose()\n",
    "labels_test = ylabels_test.values.reshape(1, 1000)-1\n",
    "labels_test_ = np.zeros((1000, 9))\n",
    "labels_test_[np.arange(1000), labels_test] = 1\n",
    "labels_test_ = labels_test_.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 1000)\n",
      "(784, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(labels_test_.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train / 255.0)\n",
    "test = np.array(test / 255.0)\n",
    "labels_ = np.array(labels_)\n",
    "labels_test_ = np.array(labels_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer (X, n, activation):\n",
    "    ndim = int(X.shape[0])\n",
    "    stddev = 2.0 / np.sqrt(ndim)\n",
    "    initialization = tf.truncated_normal((n, ndim), stddev = stddev)\n",
    "    W = tf.Variable(initialization)\n",
    "    b = tf.Variable(tf.zeros([n,1]))\n",
    "    Z = tf.matmul(W,X)+b\n",
    "    return activation(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 1\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden1, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(minibatch_size, training_epochs, features, classes, logging_step, learning_r):\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            sess.run(optimizer, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(cost, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if (epoch % logging_step == 0):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    return sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.921898\n",
      "Reached epoch 10 cost J = 0.9218837\n",
      "Reached epoch 20 cost J = 0.92188066\n",
      "Reached epoch 30 cost J = 0.9218765\n",
      "Reached epoch 40 cost J = 0.92187935\n",
      "Reached epoch 50 cost J = 0.9218688\n",
      "Reached epoch 60 cost J = 0.92186815\n",
      "Reached epoch 70 cost J = 0.92187107\n",
      "Reached epoch 80 cost J = 0.92186695\n",
      "Reached epoch 90 cost J = 0.9218663\n",
      "Reached epoch 100 cost J = 0.9218659\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1255\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.122\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 10\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden1, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.91814214\n",
      "Reached epoch 10 cost J = 0.9130484\n",
      "Reached epoch 20 cost J = 0.90429145\n",
      "Reached epoch 30 cost J = 0.89235544\n",
      "Reached epoch 40 cost J = 0.875968\n",
      "Reached epoch 50 cost J = 0.8653745\n",
      "Reached epoch 60 cost J = 0.86185783\n",
      "Reached epoch 70 cost J = 0.8607548\n",
      "Reached epoch 80 cost J = 0.8600594\n",
      "Reached epoch 90 cost J = 0.8595013\n",
      "Reached epoch 100 cost J = 0.8590235\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43375\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.458\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden1, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.88213694\n",
      "Reached epoch 10 cost J = 0.86138314\n",
      "Reached epoch 20 cost J = 0.8587065\n",
      "Reached epoch 30 cost J = 0.8572795\n",
      "Reached epoch 40 cost J = 0.8559947\n",
      "Reached epoch 50 cost J = 0.8549667\n",
      "Reached epoch 60 cost J = 0.85402477\n",
      "Reached epoch 70 cost J = 0.8531675\n",
      "Reached epoch 80 cost J = 0.85234904\n",
      "Reached epoch 90 cost J = 0.85155207\n",
      "Reached epoch 100 cost J = 0.8507872\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.495\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.486\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden2, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8798094\n",
      "Reached epoch 10 cost J = 0.8588091\n",
      "Reached epoch 20 cost J = 0.8558181\n",
      "Reached epoch 30 cost J = 0.8535606\n",
      "Reached epoch 40 cost J = 0.8516248\n",
      "Reached epoch 50 cost J = 0.8500153\n",
      "Reached epoch 60 cost J = 0.848438\n",
      "Reached epoch 70 cost J = 0.8470039\n",
      "Reached epoch 80 cost J = 0.8456037\n",
      "Reached epoch 90 cost J = 0.84426475\n",
      "Reached epoch 100 cost J = 0.84296864\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56075\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.521\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden3, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8769517\n",
      "Reached epoch 10 cost J = 0.85631067\n",
      "Reached epoch 20 cost J = 0.8524396\n",
      "Reached epoch 30 cost J = 0.8493704\n",
      "Reached epoch 40 cost J = 0.84667754\n",
      "Reached epoch 50 cost J = 0.8437507\n",
      "Reached epoch 60 cost J = 0.8412174\n",
      "Reached epoch 70 cost J = 0.8389037\n",
      "Reached epoch 80 cost J = 0.8366804\n",
      "Reached epoch 90 cost J = 0.83456475\n",
      "Reached epoch 100 cost J = 0.8325917\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.564\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.499\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden4, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.880123\n",
      "Reached epoch 10 cost J = 0.85251456\n",
      "Reached epoch 20 cost J = 0.8461901\n",
      "Reached epoch 30 cost J = 0.8415564\n",
      "Reached epoch 40 cost J = 0.8377927\n",
      "Reached epoch 50 cost J = 0.8343957\n",
      "Reached epoch 60 cost J = 0.83129907\n",
      "Reached epoch 70 cost J = 0.8283682\n",
      "Reached epoch 80 cost J = 0.82591236\n",
      "Reached epoch 90 cost J = 0.82329816\n",
      "Reached epoch 100 cost J = 0.8206604\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.606\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.532\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden5, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.88108623\n",
      "Reached epoch 10 cost J = 0.8469151\n",
      "Reached epoch 20 cost J = 0.839577\n",
      "Reached epoch 30 cost J = 0.8344778\n",
      "Reached epoch 40 cost J = 0.8302699\n",
      "Reached epoch 50 cost J = 0.8264307\n",
      "Reached epoch 60 cost J = 0.8228536\n",
      "Reached epoch 70 cost J = 0.81965864\n",
      "Reached epoch 80 cost J = 0.8162962\n",
      "Reached epoch 90 cost J = 0.8131236\n",
      "Reached epoch 100 cost J = 0.80996543\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62225\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.527\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden6, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8697267\n",
      "Reached epoch 10 cost J = 0.84070563\n",
      "Reached epoch 20 cost J = 0.832029\n",
      "Reached epoch 30 cost J = 0.8256475\n",
      "Reached epoch 40 cost J = 0.8204895\n",
      "Reached epoch 50 cost J = 0.8158241\n",
      "Reached epoch 60 cost J = 0.81183505\n",
      "Reached epoch 70 cost J = 0.80793846\n",
      "Reached epoch 80 cost J = 0.80424124\n",
      "Reached epoch 90 cost J = 0.8007677\n",
      "Reached epoch 100 cost J = 0.79774916\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66575\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.554\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden7, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8788114\n",
      "Reached epoch 10 cost J = 0.8372245\n",
      "Reached epoch 20 cost J = 0.8272937\n",
      "Reached epoch 30 cost J = 0.8201562\n",
      "Reached epoch 40 cost J = 0.8144395\n",
      "Reached epoch 50 cost J = 0.8089774\n",
      "Reached epoch 60 cost J = 0.8042155\n",
      "Reached epoch 70 cost J = 0.7995114\n",
      "Reached epoch 80 cost J = 0.79644173\n",
      "Reached epoch 90 cost J = 0.7933429\n",
      "Reached epoch 100 cost J = 0.7892767\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7055\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.559\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden8, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8722962\n",
      "Reached epoch 10 cost J = 0.8307382\n",
      "Reached epoch 20 cost J = 0.8197933\n",
      "Reached epoch 30 cost J = 0.81185013\n",
      "Reached epoch 40 cost J = 0.8048854\n",
      "Reached epoch 50 cost J = 0.79906356\n",
      "Reached epoch 60 cost J = 0.7941305\n",
      "Reached epoch 70 cost J = 0.7896292\n",
      "Reached epoch 80 cost J = 0.7856241\n",
      "Reached epoch 90 cost J = 0.78322375\n",
      "Reached epoch 100 cost J = 0.77954096\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71775\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.537\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n9 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "hidden9 = create_layer (hidden8, n9, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden9, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8586747\n",
      "Reached epoch 10 cost J = 0.8284607\n",
      "Reached epoch 20 cost J = 0.8167052\n",
      "Reached epoch 30 cost J = 0.80947244\n",
      "Reached epoch 40 cost J = 0.8024289\n",
      "Reached epoch 50 cost J = 0.79842967\n",
      "Reached epoch 60 cost J = 0.79390264\n",
      "Reached epoch 70 cost J = 0.79199606\n",
      "Reached epoch 80 cost J = 0.7861709\n",
      "Reached epoch 90 cost J = 0.78324246\n",
      "Reached epoch 100 cost J = 0.7816606\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73475\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.519\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n9 = 100\n",
    "n10 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "hidden9 = create_layer (hidden8, n9, activation = tf.nn.relu)\n",
    "hidden10 = create_layer (hidden9, n10, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden10, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8685723\n",
      "Reached epoch 10 cost J = 0.82572806\n",
      "Reached epoch 20 cost J = 0.8133874\n",
      "Reached epoch 30 cost J = 0.8045881\n",
      "Reached epoch 40 cost J = 0.79823804\n",
      "Reached epoch 50 cost J = 0.79197687\n",
      "Reached epoch 60 cost J = 0.7884622\n",
      "Reached epoch 70 cost J = 0.78344536\n",
      "Reached epoch 80 cost J = 0.78053504\n",
      "Reached epoch 90 cost J = 0.77544326\n",
      "Reached epoch 100 cost J = 0.773525\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75675\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n9 = 100\n",
    "n10 = 100\n",
    "n11 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "hidden9 = create_layer (hidden8, n9, activation = tf.nn.relu)\n",
    "hidden10 = create_layer (hidden9, n10, activation = tf.nn.relu)\n",
    "hidden11 = create_layer (hidden10, n11, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden11, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.860754\n",
      "Reached epoch 10 cost J = 0.82153344\n",
      "Reached epoch 20 cost J = 0.81092453\n",
      "Reached epoch 30 cost J = 0.80346847\n",
      "Reached epoch 40 cost J = 0.7978005\n",
      "Reached epoch 50 cost J = 0.792181\n",
      "Reached epoch 60 cost J = 0.7880161\n",
      "Reached epoch 70 cost J = 0.7831659\n",
      "Reached epoch 80 cost J = 0.7798553\n",
      "Reached epoch 90 cost J = 0.77669\n",
      "Reached epoch 100 cost J = 0.772399\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7715\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.525\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n9 = 100\n",
    "n10 = 100\n",
    "n11 = 100\n",
    "n12 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "hidden9 = create_layer (hidden8, n9, activation = tf.nn.relu)\n",
    "hidden10 = create_layer (hidden9, n10, activation = tf.nn.relu)\n",
    "hidden11 = create_layer (hidden10, n11, activation = tf.nn.relu)\n",
    "hidden12 = create_layer (hidden11, n12, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden12, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8676177\n",
      "Reached epoch 10 cost J = 0.8206233\n",
      "Reached epoch 20 cost J = 0.80955595\n",
      "Reached epoch 30 cost J = 0.8007181\n",
      "Reached epoch 40 cost J = 0.7951066\n",
      "Reached epoch 50 cost J = 0.7892435\n",
      "Reached epoch 60 cost J = 0.7844526\n",
      "Reached epoch 70 cost J = 0.77950627\n",
      "Reached epoch 80 cost J = 0.7772491\n",
      "Reached epoch 90 cost J = 0.77260447\n",
      "Reached epoch 100 cost J = 0.7720884\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77525\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n9 = 100\n",
    "n10 = 100\n",
    "n11 = 100\n",
    "n12 = 100\n",
    "n13 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "hidden9 = create_layer (hidden8, n9, activation = tf.nn.relu)\n",
    "hidden10 = create_layer (hidden9, n10, activation = tf.nn.relu)\n",
    "hidden11 = create_layer (hidden10, n11, activation = tf.nn.relu)\n",
    "hidden12 = create_layer (hidden11, n12, activation = tf.nn.relu)\n",
    "hidden13 = create_layer (hidden12, n13, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden13, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8568012\n",
      "Reached epoch 10 cost J = 0.8209378\n",
      "Reached epoch 20 cost J = 0.81051606\n",
      "Reached epoch 30 cost J = 0.80157924\n",
      "Reached epoch 40 cost J = 0.7942925\n",
      "Reached epoch 50 cost J = 0.7944915\n",
      "Reached epoch 60 cost J = 0.78936976\n",
      "Reached epoch 70 cost J = 0.78043634\n",
      "Reached epoch 80 cost J = 0.7776817\n",
      "Reached epoch 90 cost J = 0.7736091\n",
      "Reached epoch 100 cost J = 0.7761906\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73125\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.484\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n9 = 100\n",
    "n10 = 100\n",
    "n11 = 100\n",
    "n12 = 100\n",
    "n13 = 100\n",
    "n14 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "hidden9 = create_layer (hidden8, n9, activation = tf.nn.relu)\n",
    "hidden10 = create_layer (hidden9, n10, activation = tf.nn.relu)\n",
    "hidden11 = create_layer (hidden10, n11, activation = tf.nn.relu)\n",
    "hidden12 = create_layer (hidden11, n12, activation = tf.nn.relu)\n",
    "hidden13 = create_layer (hidden12, n13, activation = tf.nn.relu)\n",
    "hidden14 = create_layer (hidden13, n14, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden14, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8619158\n",
      "Reached epoch 10 cost J = 0.8216425\n",
      "Reached epoch 20 cost J = 0.81033516\n",
      "Reached epoch 30 cost J = 0.80214745\n",
      "Reached epoch 40 cost J = 0.7945472\n",
      "Reached epoch 50 cost J = 0.79141074\n",
      "Reached epoch 60 cost J = 0.78622836\n",
      "Reached epoch 70 cost J = 0.7802055\n",
      "Reached epoch 80 cost J = 0.7786621\n",
      "Reached epoch 90 cost J = 0.77537364\n",
      "Reached epoch 100 cost J = 0.77441156\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77325\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.534\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n9 = 100\n",
    "n10 = 100\n",
    "n11 = 100\n",
    "n12 = 100\n",
    "n13 = 100\n",
    "n14 = 100\n",
    "n15 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "hidden9 = create_layer (hidden8, n9, activation = tf.nn.relu)\n",
    "hidden10 = create_layer (hidden9, n10, activation = tf.nn.relu)\n",
    "hidden11 = create_layer (hidden10, n11, activation = tf.nn.relu)\n",
    "hidden12 = create_layer (hidden11, n12, activation = tf.nn.relu)\n",
    "hidden13 = create_layer (hidden12, n13, activation = tf.nn.relu)\n",
    "hidden14 = create_layer (hidden13, n14, activation = tf.nn.relu)\n",
    "hidden15 = create_layer (hidden14, n15, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden15, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.85862225\n",
      "Reached epoch 10 cost J = 0.8221298\n",
      "Reached epoch 20 cost J = 0.8143471\n",
      "Reached epoch 30 cost J = 0.80220073\n",
      "Reached epoch 40 cost J = 0.79877335\n",
      "Reached epoch 50 cost J = 0.7910806\n",
      "Reached epoch 60 cost J = 0.7867185\n",
      "Reached epoch 70 cost J = 0.7878935\n",
      "Reached epoch 80 cost J = 0.7760061\n",
      "Reached epoch 90 cost J = 0.77999324\n",
      "Reached epoch 100 cost J = 0.77483517\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.745\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n9 = 100\n",
    "n10 = 100\n",
    "n11 = 100\n",
    "n12 = 100\n",
    "n13 = 100\n",
    "n14 = 100\n",
    "n15 = 100\n",
    "n16 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "hidden9 = create_layer (hidden8, n9, activation = tf.nn.relu)\n",
    "hidden10 = create_layer (hidden9, n10, activation = tf.nn.relu)\n",
    "hidden11 = create_layer (hidden10, n11, activation = tf.nn.relu)\n",
    "hidden12 = create_layer (hidden11, n12, activation = tf.nn.relu)\n",
    "hidden13 = create_layer (hidden12, n13, activation = tf.nn.relu)\n",
    "hidden14 = create_layer (hidden13, n14, activation = tf.nn.relu)\n",
    "hidden15 = create_layer (hidden14, n15, activation = tf.nn.relu)\n",
    "hidden16 = create_layer (hidden15, n16, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden16, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.8581884\n",
      "Reached epoch 10 cost J = 0.8294467\n",
      "Reached epoch 20 cost J = 0.8167777\n",
      "Reached epoch 30 cost J = 0.8057739\n",
      "Reached epoch 40 cost J = 0.8085398\n",
      "Reached epoch 50 cost J = 0.7929648\n",
      "Reached epoch 60 cost J = 0.787377\n",
      "Reached epoch 70 cost J = 0.7843435\n",
      "Reached epoch 80 cost J = 0.7898599\n",
      "Reached epoch 90 cost J = 0.78348035\n",
      "Reached epoch 100 cost J = 0.7807209\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.707\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.484\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "n_dim = 784\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "n3 = 100\n",
    "n4 = 100\n",
    "n5 = 100\n",
    "n6 = 100\n",
    "n7 = 100\n",
    "n8 = 100\n",
    "n9 = 100\n",
    "n10 = 100\n",
    "n11 = 100\n",
    "n12 = 100\n",
    "n13 = 100\n",
    "n14 = 100\n",
    "n15 = 100\n",
    "n16 = 100\n",
    "n17 = 100\n",
    "n_outputs = 9\n",
    "\n",
    "tf.set_random_seed(5)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [9, None])\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "hidden1 = create_layer (X, n1, activation = tf.nn.relu)\n",
    "hidden2 = create_layer (hidden1, n2, activation = tf.nn.relu)\n",
    "hidden3 = create_layer (hidden2, n3, activation = tf.nn.relu)\n",
    "hidden4 = create_layer (hidden3, n4, activation = tf.nn.relu)\n",
    "hidden5 = create_layer (hidden4, n5, activation = tf.nn.relu)\n",
    "hidden6 = create_layer (hidden5, n6, activation = tf.nn.relu)\n",
    "hidden7 = create_layer (hidden6, n7, activation = tf.nn.relu)\n",
    "hidden8 = create_layer (hidden7, n8, activation = tf.nn.relu)\n",
    "hidden9 = create_layer (hidden8, n9, activation = tf.nn.relu)\n",
    "hidden10 = create_layer (hidden9, n10, activation = tf.nn.relu)\n",
    "hidden11 = create_layer (hidden10, n11, activation = tf.nn.relu)\n",
    "hidden12 = create_layer (hidden11, n12, activation = tf.nn.relu)\n",
    "hidden13 = create_layer (hidden12, n13, activation = tf.nn.relu)\n",
    "hidden14 = create_layer (hidden13, n14, activation = tf.nn.relu)\n",
    "hidden15 = create_layer (hidden14, n15, activation = tf.nn.relu)\n",
    "hidden16 = create_layer (hidden15, n16, activation = tf.nn.relu)\n",
    "hidden17 = create_layer (hidden16, n17, activation = tf.nn.relu)\n",
    "outputs = create_layer (hidden17, n_outputs, activation = tf.identity)\n",
    "y_ = tf.nn.softmax(outputs)\n",
    "\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step, \n",
    "                 learning_r, number_neurons, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = nan\n",
      "Reached epoch 10 cost J = nan\n",
      "Reached epoch 20 cost J = nan\n",
      "Reached epoch 30 cost J = nan\n",
      "Reached epoch 40 cost J = nan\n",
      "Reached epoch 50 cost J = nan\n",
      "Reached epoch 60 cost J = nan\n",
      "Reached epoch 70 cost J = nan\n",
      "Reached epoch 80 cost J = nan\n",
      "Reached epoch 90 cost J = nan\n",
      "Reached epoch 100 cost J = nan\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = model (50, 100, train, labels_,logging_step = 10, learning_r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "print (\"Accuracy:\", accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
